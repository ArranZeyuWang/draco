{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Bugs\n",
    "\n",
    "Use this notebook to find wrong predicitons. We can then later visualize the pairs of specs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from draco.learn import data_util\n",
    "from draco.learn import linear\n",
    "from sklearn import svm\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev, _ = data_util.load_data()\n",
    "\n",
    "X = train_dev.positive - train_dev.negative\n",
    "X = X.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "\n",
    "Cross validate the model by running it over various subsets of the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found bug 748\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "bug_idx = []\n",
    "bug_confidence = []\n",
    "\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    \n",
    "    y_train = np.ones(len(X_train))\n",
    "    \n",
    "    # swap first example\n",
    "    X_train[0] = -X_train[0]\n",
    "    y_train[0] = -y_train[0]\n",
    "\n",
    "    clf = svm.LinearSVC(C=1, fit_intercept=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    if clf.predict(X_test)[0] != 1:\n",
    "        bug_idx.append(test_index[0])\n",
    "        bug_confidence.append(clf.decision_function(X_test)[0])\n",
    "        print(\"Found bug\", test_index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([748], [-0.18631813592593938])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bug_idx, bug_confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1760], dtype='int64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the indexes in the original data\n",
    "bugs = train_dev.index[bug_idx]\n",
    "bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_data = data_util.load_neg_pos_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generate better data\n",
    "\n",
    "vals = [{\n",
    "    'q1': round(random.normalvariate(2, 2), 3),\n",
    "    'q2': round(random.normalvariate(2, 2), 3),\n",
    "    'n': random.randint(0,7)\n",
    "} for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_specs = []\n",
    "\n",
    "for i, bi in enumerate(bugs):\n",
    "    example = pos_neg_data[bi]\n",
    "    \n",
    "    negative = example.negative\n",
    "    positive = example.positive\n",
    "    \n",
    "    negative['data'] = {\n",
    "        'values': vals\n",
    "    }\n",
    "    positive['data'] = {\n",
    "        'values': vals\n",
    "    }\n",
    "    bug_specs.append({\n",
    "        'negative': negative,\n",
    "        'positive': positive,\n",
    "        'confidence': bug_confidence[i]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'confidence': -0.18631813592593938,\n",
       "  'negative': {'data': {'values': [{'n': 3, 'q1': 3.423, 'q2': 1.115},\n",
       "     {'n': 1, 'q1': 2.607, 'q2': 4.2},\n",
       "     {'n': 4, 'q1': 3.515, 'q2': 6.028},\n",
       "     {'n': 4, 'q1': 1.57, 'q2': 2.401},\n",
       "     {'n': 2, 'q1': 3.238, 'q2': -0.063},\n",
       "     {'n': 6, 'q1': 4.194, 'q2': 0.738},\n",
       "     {'n': 6, 'q1': 1.464, 'q2': 0.718},\n",
       "     {'n': 2, 'q1': 2.783, 'q2': -0.224},\n",
       "     {'n': 2, 'q1': -0.72, 'q2': 0.27},\n",
       "     {'n': 6, 'q1': 4.512, 'q2': 3.771}]},\n",
       "   'encoding': {'x': {'field': 'n', 'type': 'ordinal'},\n",
       "    'y': {'aggregate': 'mean', 'field': 'q2', 'type': 'quantitative'}},\n",
       "   'mark': 'bar'},\n",
       "  'positive': {'data': {'values': [{'n': 3, 'q1': 3.423, 'q2': 1.115},\n",
       "     {'n': 1, 'q1': 2.607, 'q2': 4.2},\n",
       "     {'n': 4, 'q1': 3.515, 'q2': 6.028},\n",
       "     {'n': 4, 'q1': 1.57, 'q2': 2.401},\n",
       "     {'n': 2, 'q1': 3.238, 'q2': -0.063},\n",
       "     {'n': 6, 'q1': 4.194, 'q2': 0.738},\n",
       "     {'n': 6, 'q1': 1.464, 'q2': 0.718},\n",
       "     {'n': 2, 'q1': 2.783, 'q2': -0.224},\n",
       "     {'n': 2, 'q1': -0.72, 'q2': 0.27},\n",
       "     {'n': 6, 'q1': 4.512, 'q2': 3.771}]},\n",
       "   'encoding': {'x': {'field': 'n', 'type': 'nominal'},\n",
       "    'y': {'aggregate': 'mean', 'field': 'q2', 'type': 'quantitative'}},\n",
       "   'mark': 'line'}}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bug_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bugs/bugs.json', 'w') as f:\n",
    "    json.dump(bug_specs, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
